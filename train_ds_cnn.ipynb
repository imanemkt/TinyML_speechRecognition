{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15cf55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minfo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, DepthwiseConv2D, GlobalAveragePooling2D, Dense, Reshape\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n",
    "\n",
    "# --- 1. Chargement des données ---\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "# --- 2. Récupérer le nombre de classes ---\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f307fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Mise en forme des données ---\n",
    "# On reshape les MFCCs pour simuler une \"image\" (pour Conv2D)\n",
    "# Hypothèse : MFCCs moyennés → vecteur de taille (13,) → on reshape en (13, 1, 1)\n",
    "X_train = X_train.reshape(-1, 13, 1, 1)\n",
    "X_test = X_test.reshape(-1, 13, 1, 1)\n",
    "\n",
    "# One-hot encoding des labels\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# --- 4. Définition du modèle DS-CNN ---\n",
    "def build_ds_cnn_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # First conv layer\n",
    "    x = Conv2D(64, kernel_size=(3, 1), padding='same', activation=None)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Depthwise separable convolutions (x3)\n",
    "    for _ in range(3):\n",
    "        x = DepthwiseConv2D(kernel_size=(3, 1), padding='same', activation=None)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(64, kernel_size=(1, 1), padding='same', activation=None)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "    # Global average pooling + dense softmax\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# --- 5. Compilation ---\n",
    "model = build_ds_cnn_model((13, 1, 1), num_classes)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b7b288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0000e+00 - loss: 9.3276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 9.3277 - val_accuracy: 0.0000e+00 - val_loss: 9.3597\n",
      "Epoch 2/50\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.0000e+00 - loss: 9.2101 - val_accuracy: 0.0000e+00 - val_loss: 9.5598\n",
      "Epoch 3/50\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 4.6485e-04 - loss: 9.1437 - val_accuracy: 0.0000e+00 - val_loss: 9.9169\n",
      "Epoch 4/50\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 3.0626e-04 - loss: 8.9983 - val_accuracy: 0.0000e+00 - val_loss: 10.6601\n",
      "Epoch 5/50\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0011 - loss: 8.8464 - val_accuracy: 0.0000e+00 - val_loss: 11.2971\n",
      "Epoch 6/50\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 3.0051e-04 - loss: 8.6880 - val_accuracy: 0.0000e+00 - val_loss: 12.2292\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 9.3598\n",
      "✅ Test Accuracy : 0.00%\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Entraînement ---\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"best_ds_cnn_model.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_data=(X_test, y_test_cat),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# --- 7. Évaluation ---\n",
    "loss, acc = model.evaluate(X_test, y_test_cat)\n",
    "print(f\"✅ Test Accuracy : {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35aa97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
